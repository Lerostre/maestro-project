{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22074823-b7ba-4198-8fd4-32ebb7a97d17",
   "metadata": {},
   "source": [
    "Здесь лежат мои потуги по сбору датафрейма. Ничего специально не структурировал, это не тот ноутбук, на который нужно прямо смотреть, я воспользовался им один раз, забыл и ушёл. Основные идеи тут есть, какие-то мелочи скорее всего потерялись"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48038914-915d-439b-9023-75ce29aa5ed6",
   "metadata": {},
   "source": [
    "К сожалению, книги Евгения Николаевича не распознаны нормально, поэтому надо как-то из этого выкручиваться. Выход первый - забить и распарсить пдфку готовыми библиотеками. Выход так себе, он обрабатывает только один язык, а маэстро у нас полиглот, к тому же обрабатывает не очень, ошибки видно даже невооружённым взглядом, плюсы - он делает всё быстро, по итогу это я сразу отмёл.    \n",
    "Вариант 2 - прогнать через OCR. Для этого надо превратить пдф в кучу картинок и обработать их тессерактом. Тессеракт ставится через всем известное место, нужно установить его в питоне и отдельно в ОС, нужно прописать отдельно к нему путь, ну и сам процесс обработки довольно долгий. По-моему, у меня заняло примерно час. Зато качество - моё почтение, ошибок очень мало, и распознаны оба алфавита. Ну разве что про греческий я забыл, я не знал, что он там вообще есть"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746a07d5-ae58-407e-a739-0ce80dc84179",
   "metadata": {},
   "source": [
    "Ставим пререквизиты, если надо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50bd6403-c41d-428c-ab8e-c3b4ee6a5e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdf2image in c:\\users\\maloy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.16.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\maloy\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pdf2image) (9.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install pdf2image\n",
    "!pip install opencv-python\n",
    "!pip install pytesseract\n",
    "!pip install tesseract\n",
    "!pip install tesseract-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "453e6b1c-105e-4025-8da8-ac9807b4c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# прописываем путь к СВОЕМУ тессеракту на СВОЁМ компе\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:/OCR/Tesseract/tesseract.exe' # надо менять, если путь другой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "defcc6d6-fa2e-4771-9b3a-2aaa3192fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "# сперва можно просто всё импортировать и разбить пдф на странички\n",
    "# попплер тоже вредный, может понадобиться его отдельно скачать\n",
    "pages = convert_from_path('maestro_book1.pdf', 100, poppler_path=r\"poppler-0.68.0\\bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "faafc271-418f-4d69-98e5-2066ebf1671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text, num):\n",
    "    \"\"\"Обрабатывает текст первой книги следующим образом:\n",
    "    заменяет все дефисы, разбивает на слова, убирает первые\n",
    "    два - это верхний колонтинул, убирает последние 2 или 3,\n",
    "    разнится от чётности странные, это нижний колонтинул\"\"\"\n",
    "    foot = 2 if num % 2 == 0 else 3\n",
    "    return \" \".join(x for x in text.replace(\"-\\n\", \"\").split(\"\\n\")[2:-foot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0c56b7fb-846c-4190-9c8f-03992da29624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 402/402 [11:10<00:00,  1.67s/it]\n"
     ]
    }
   ],
   "source": [
    "page_text = []\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(8, 410)):\n",
    "    # сохраняем картинку\n",
    "    pages[i].save(f'out{i}.jpg', 'JPEG')\n",
    "    # смотрим на картинку и анализируем\n",
    "    imgcv = cv2.imread(f'out{i}.jpg')\n",
    "    imgcv = cv2.cvtColor(imgcv, cv2.COLOR_BGR2RGB)\n",
    "    text = pytesseract.image_to_string(imgcv,  lang='eng+rus')\n",
    "    # достаём текст и засовываем в список\n",
    "    page_text.append(clean(text, i-1))\n",
    "    #9-409"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "82700da0-3e96-45a9-a2e2-f13ba36509fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# решил не бить на страницы, непонятно, как их клеить, если не руками\n",
    "full_text = \"\".join(x for x in page_text)\n",
    "\n",
    "# сохраняем результат\n",
    "with open(\"maestro_book1.txt\", \"w\", encoding=\"utf-8\") as g:\n",
    "    g.write(full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6502012-37b0-4dad-9c88-390af0725638",
   "metadata": {},
   "source": [
    "Это была первая книга, далее копипаста, всё то же самое для второй, только со своей спецификой. Точно так же чищу дефисы, хедеры, футеры, пишу в файл. Единственная разница - он уже распознан, тессеракт будет оверкиллом, можно делать через пдфридер, заодно будет указан второй способ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c580deb0-eb43-4974-ae78-0b6a7d1b51b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = convert_from_path('maestro_book2.pdf', 100, poppler_path=r\"poppler-0.68.0\\bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "3fedcf7b-6d24-4db5-8a00-99bcad583332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean2(text, num):\n",
    "    header = 3 if num % 2 == 0 else 7\n",
    "    text = \" \".join(x for x in text.split()[header:] if x != \"\")\n",
    "    text = re.sub(r\"[\\s]{2,}\", \"\", text.replace(\"\\xad\", \" \"))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "cef9f1c6-c545-4833-b5dc-5e1cd678fc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 856/856 [01:12<00:00, 11.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "reader = PdfReader(\"maestro_book2.pdf\")\n",
    "text = \" \".join(x for x in reader.pages[8].extract_text().split()[2:])\n",
    "text = re.sub(r\"[\\s]{2,}\", \"\", text.replace(\"\\xad\", \" \"))  # самая первая страница - красивая\n",
    "for num in tqdm(range(9, 865)):\n",
    "    text += clean2(reader.pages[num].extract_text(), num-1)\n",
    "    \n",
    "with open(\"maestro_book2.txt\", \"w\", encoding=\"utf-8\") as g:\n",
    "    g.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b22aec-fdab-40fe-b9f5-7010c471114b",
   "metadata": {},
   "source": [
    "Теперь надо придумать, как вытащить статьи Евгения Николаевича. Опять писать краулер, получается, как это надоело, если честно..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "5a884784-3ce4-40b6-b44e-171120c41e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effcd3be-4431-4cf7-a9fa-fefb31eb73ec",
   "metadata": {},
   "source": [
    "Со странички в вк уже удобно доступны все посты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "e5bfb4fd-020e-40ca-bdc3-25eefa928f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://vk.com/@evgenyponasenkov\"\n",
    "\n",
    "session = requests.session()\n",
    "session.trust_env = False\n",
    "\n",
    "req = session.get(url)\n",
    "page = req.text\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "# все переходы на посты лежат в \"а\"\n",
    "a = soup.find_all('a', href=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "a49a73ef-207a-412f-b86e-269aefdc0d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# промежуточный датафрейм для вк\n",
    "df = pd.DataFrame(columns=[\"url\", \"title\", \"date\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "ecb12c38-da38-4687-b065-29254a7a9070",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs = [\"https://vk.com\"+i[\"href\"] for i in a[3:-1]]  # всё, что вытащилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "33bedde3-60b0-41db-8a7d-6d9ef4820d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:03<00:00,  6.05it/s]\n"
     ]
    }
   ],
   "source": [
    "for href in tqdm(hrefs):\n",
    "    req = session.get(href)\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    text = \" \".join(x.text for x in soup.find_all(\"p\"))\n",
    "    title = soup.find(\"h1\").text\n",
    "    # поскольку вк писали люди, достать оттуда всю метаинфу несложно\n",
    "\n",
    "    # мне лень это всё в группы клеить\n",
    "    date = re.findall(r\".{4}-.{2}-.{2}\",\n",
    "                      re.findall(r'\"datePublished\".*T', page)[0])[0]\n",
    "    df = pd.concat([df, pd.DataFrame({\"url\": href, \"title\": title,\n",
    "                                      \"date\": date, \"text\": text}, index=[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "331d6e30-9551-49bb-9753-835cf65e2b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-kutuzovskii-p...</td>\n",
       "      <td>Кутузовский план Кремля (27. 12. 2011)</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>Начну, простите, с конца. Да, митинги 10-го и ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-istorik-evgen...</td>\n",
       "      <td>Историк Евгений Понасенков: Россия - это ходяч...</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>Историк, режиссер, оперный певец и общественны...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-dva-gogolya-i...</td>\n",
       "      <td>Два Гоголя, или Неизбежность поражения</td>\n",
       "      <td>2021-02-14</td>\n",
       "      <td>Не секрет, что общество, эпоха, семья - да, чт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-otprazdnuem-k...</td>\n",
       "      <td>Отпразднуем капитуляцию кремлевского гарнизона...</td>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>Начну не с того, что правительство России не в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-gosudarstvenn...</td>\n",
       "      <td>Государственный переворот и «НТВшники» (10. 04...</td>\n",
       "      <td>2021-01-21</td>\n",
       "      <td>Как это ни печально, но скоро основатель движе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-1812-ubileiny...</td>\n",
       "      <td>1812: юбилейный зомбоящик, верни дворянам масл...</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>Превеликая кампания по зомбированию населения ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-1812-god-otve...</td>\n",
       "      <td>1812 год: ответ историка Патриарху Кириллу (10...</td>\n",
       "      <td>2020-11-26</td>\n",
       "      <td>В недавнем азартном отмечании юбилея войны 181...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-evgenialnyi-s...</td>\n",
       "      <td>ЕвГениальный список архитекторов</td>\n",
       "      <td>2020-09-16</td>\n",
       "      <td>Альбомы по всей архитектуре Древнего Египта, Г...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-intelligentsk...</td>\n",
       "      <td>Интеллигентский мазохизм — страшнее терроризма...</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>Господа-товарищи, всему же есть пределы! Вчера...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-chudovischnye...</td>\n",
       "      <td>Чудовищные уроки 1917 года: убийство как истор...</td>\n",
       "      <td>2020-08-09</td>\n",
       "      <td>Надо признать, что в начале прошлого века коре...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-est-takaya-pr...</td>\n",
       "      <td>Есть такая профессия – народ отвлекать (15 янв...</td>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>Вы только вдумайтесь в этот монструозный бред:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-evgenialnyi-s...</td>\n",
       "      <td>ЕвГениальный список фильмов – Часть I</td>\n",
       "      <td>2020-06-03</td>\n",
       "      <td>«Большой вальс» (1939) «Театр» (Вия Артмане) «...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-vladimir-vlad...</td>\n",
       "      <td>Владимир Владимирович, я не хочу жить ни при к...</td>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>Превозмогая боль Пескова от злокачественных сл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-iz-dvuh-zol-m...</td>\n",
       "      <td>Из двух «зол» мы выбрали обе, или здравствуй Н...</td>\n",
       "      <td>2020-07-14</td>\n",
       "      <td>Друзья мои, прекрасен наш союз (на «Эхе»)… но ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-s-chego-nachi...</td>\n",
       "      <td>С чего начинается фашизм на родине? (22 август...</td>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>А я все думал: ну, когда же начнутся дружины, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-mezhdu-popom-...</td>\n",
       "      <td>Между попом и божеством: три часа свободы и сч...</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>Ну, что: давайте, если хотите, поговорим об ак...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-evgenialnyi-s...</td>\n",
       "      <td>ЕвГениальный список художников</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>Сандро Боттичелли  Леонардо да Винчи  Витторе ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-intelligentsk...</td>\n",
       "      <td>Интеллигентский мазохизм — страшнее терроризма...</td>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>Господа-товарищи, всему же есть пределы! Вчера...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-terakt-v-pari...</td>\n",
       "      <td>Теракт в Париже – не теракт, а война!</td>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>Пора перестать прятать голову в песок: зверски...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-u-zapada-vseg...</td>\n",
       "      <td>У Запада всего одна ошибка — но смертельная</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>В Европе построили лучший из вариантов жизни з...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://vk.com/@evgenyponasenkov-kutuzovskii-p...   \n",
       "0  https://vk.com/@evgenyponasenkov-istorik-evgen...   \n",
       "0  https://vk.com/@evgenyponasenkov-dva-gogolya-i...   \n",
       "0  https://vk.com/@evgenyponasenkov-otprazdnuem-k...   \n",
       "0  https://vk.com/@evgenyponasenkov-gosudarstvenn...   \n",
       "0  https://vk.com/@evgenyponasenkov-1812-ubileiny...   \n",
       "0  https://vk.com/@evgenyponasenkov-1812-god-otve...   \n",
       "0  https://vk.com/@evgenyponasenkov-evgenialnyi-s...   \n",
       "0  https://vk.com/@evgenyponasenkov-intelligentsk...   \n",
       "0  https://vk.com/@evgenyponasenkov-chudovischnye...   \n",
       "0  https://vk.com/@evgenyponasenkov-est-takaya-pr...   \n",
       "0  https://vk.com/@evgenyponasenkov-evgenialnyi-s...   \n",
       "0  https://vk.com/@evgenyponasenkov-vladimir-vlad...   \n",
       "0  https://vk.com/@evgenyponasenkov-iz-dvuh-zol-m...   \n",
       "0  https://vk.com/@evgenyponasenkov-s-chego-nachi...   \n",
       "0  https://vk.com/@evgenyponasenkov-mezhdu-popom-...   \n",
       "0  https://vk.com/@evgenyponasenkov-evgenialnyi-s...   \n",
       "0  https://vk.com/@evgenyponasenkov-intelligentsk...   \n",
       "0  https://vk.com/@evgenyponasenkov-terakt-v-pari...   \n",
       "0  https://vk.com/@evgenyponasenkov-u-zapada-vseg...   \n",
       "\n",
       "                                               title        date  \\\n",
       "0             Кутузовский план Кремля (27. 12. 2011)  2021-02-24   \n",
       "0  Историк Евгений Понасенков: Россия - это ходяч...  2021-02-17   \n",
       "0             Два Гоголя, или Неизбежность поражения  2021-02-14   \n",
       "0  Отпразднуем капитуляцию кремлевского гарнизона...  2021-01-27   \n",
       "0  Государственный переворот и «НТВшники» (10. 04...  2021-01-21   \n",
       "0  1812: юбилейный зомбоящик, верни дворянам масл...  2020-11-30   \n",
       "0  1812 год: ответ историка Патриарху Кириллу (10...  2020-11-26   \n",
       "0                   ЕвГениальный список архитекторов  2020-09-16   \n",
       "0  Интеллигентский мазохизм — страшнее терроризма...  2020-08-17   \n",
       "0  Чудовищные уроки 1917 года: убийство как истор...  2020-08-09   \n",
       "0  Есть такая профессия – народ отвлекать (15 янв...  2020-07-31   \n",
       "0              ЕвГениальный список фильмов – Часть I  2020-06-03   \n",
       "0  Владимир Владимирович, я не хочу жить ни при к...  2020-07-23   \n",
       "0  Из двух «зол» мы выбрали обе, или здравствуй Н...  2020-07-14   \n",
       "0  С чего начинается фашизм на родине? (22 август...  2020-07-13   \n",
       "0  Между попом и божеством: три часа свободы и сч...  2020-07-06   \n",
       "0                    ЕвГениальный список художников   2020-07-03   \n",
       "0  Интеллигентский мазохизм — страшнее терроризма...  2020-06-26   \n",
       "0              Теракт в Париже – не теракт, а война!  2020-06-14   \n",
       "0       У Запада всего одна ошибка — но смертельная   2020-06-10   \n",
       "\n",
       "                                                text  \n",
       "0  Начну, простите, с конца. Да, митинги 10-го и ...  \n",
       "0  Историк, режиссер, оперный певец и общественны...  \n",
       "0  Не секрет, что общество, эпоха, семья - да, чт...  \n",
       "0  Начну не с того, что правительство России не в...  \n",
       "0  Как это ни печально, но скоро основатель движе...  \n",
       "0  Превеликая кампания по зомбированию населения ...  \n",
       "0  В недавнем азартном отмечании юбилея войны 181...  \n",
       "0  Альбомы по всей архитектуре Древнего Египта, Г...  \n",
       "0  Господа-товарищи, всему же есть пределы! Вчера...  \n",
       "0  Надо признать, что в начале прошлого века коре...  \n",
       "0  Вы только вдумайтесь в этот монструозный бред:...  \n",
       "0  «Большой вальс» (1939) «Театр» (Вия Артмане) «...  \n",
       "0  Превозмогая боль Пескова от злокачественных сл...  \n",
       "0  Друзья мои, прекрасен наш союз (на «Эхе»)… но ...  \n",
       "0  А я все думал: ну, когда же начнутся дружины, ...  \n",
       "0  Ну, что: давайте, если хотите, поговорим об ак...  \n",
       "0  Сандро Боттичелли  Леонардо да Винчи  Витторе ...  \n",
       "0  Господа-товарищи, всему же есть пределы! Вчера...  \n",
       "0  Пора перестать прятать голову в песок: зверски...  \n",
       "0  В Европе построили лучший из вариантов жизни з...  "
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "ea061987-3970-4a21-9204-f637e68ea98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"url\", \"title\", \"date\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "f35ada16-76d9-439c-963f-c36804dd87e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 2):\n",
    "\n",
    "    url = f\"https://www.mk.ru/blogs/blog-evgeniya-ponasenkova.html?page={i}\"\n",
    "\n",
    "    session = requests.session()\n",
    "    session.trust_env = False\n",
    "\n",
    "    req = session.get(url)\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "    a = soup.find_all('a', href=True)\n",
    "    refs = []\n",
    "    for i in a:\n",
    "        href = i[\"href\"]\n",
    "        if \"https://www.mk.ru/blogs/posts/\" in href:\n",
    "            refs.append(href)\n",
    "\n",
    "    for href in refs[:-5]:  # 5 последних на всех страницах\n",
    "        sub_req = session.get(href)\n",
    "        sub_page = sub_req.text\n",
    "        sub_soup = BeautifulSoup(sub_page, 'html.parser')\n",
    "        text = \" \".join(x.text for x in sub_soup.find_all(\"p\"))\n",
    "        text = text.replace(\"\\n\", \" \").split()\n",
    "        text = text[:-275] # это реклама\n",
    "        title = sub_soup.find(\"h1\").text + \". Блог Евгения Понасенкова на mk.ru\"\n",
    "        date = \" \".join(text[i] for i in range(3))\n",
    "        text = \" \".join(x for x in text[8:])  # до этого не важная информация\n",
    "        df = pd.concat([df, pd.DataFrame({\"url\": href, \"title\": title, \"date\": date, \"text\": text}, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97ab4ff-0eca-4ead-b9da-7bd3efa1ebdb",
   "metadata": {},
   "source": [
    "Где-то тут я опомнился, что я не записал тексты книг в датафреймы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36647cf2-8da5-4faf-9169-1a0b17d60381",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"maestro_book2.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "df = pd.concat([df, pd.DataFrame({\"url\": \"https://www.moscowbooks.ru/bookinist/book/308360/\",\n",
    "                                  \"title\": 'Первая научная история войны 1812 года',\n",
    "                                  \"date\": 2018,\n",
    "                                  \"text\": text}, index=[0])])\n",
    "\n",
    "with open(\"maestro_book1.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "df = pd.concat([df, pd.DataFrame({\"url\": \"https://www.ozon.ru/product/pervaya-nauchnaya-istoriya-voyny-1812-goda-trete-izdanie-ponasenkov-evgeniy-nikolaevich-250460112/?sh=cAScFiM5SQ\",\n",
    "                                  \"title\": 'Правда о войне 1812 года',\n",
    "                                  \"date\": 2004,\n",
    "                                  \"text\": text}, index=[0])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "a708c22f-7935-40f0-83ee-7cb31df0a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "04bd8d6b-8981-4ede-9f8e-ea10958c137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # идея была в том, чтобы присвоить токену ключ,\n",
    "    # поскольку я кучу раз применяю функцию, нужно хранить счётчик вне\n",
    "    global i\n",
    "    # параллельно заполняется база морфохарактеристик,\n",
    "    # которые, как выяснилось, не нужны, но я засуну куда-нибудь\n",
    "    global df2\n",
    "\n",
    "    # токенизирую, вырезаю токены, делаю морфоразбор\n",
    "    lowered = tokenizer.tokenize(text.lower())\n",
    "    forms = predictor.predict(lowered)\n",
    "    clear_output()  # почему нет verbose у предиктора вне моего понимания\n",
    "    tokens = {}  # словарь токенов предложения, для максимальной скорости\n",
    "    lemmas = {}  # леммы аналогично\n",
    "\n",
    "    for form in forms:\n",
    "        word = form.word\n",
    "        lemma = form.normal_form\n",
    "\n",
    "        # делаю ссылки, если слово есть, то она одна, если\n",
    "        # несколько, будет ссылаться на несколько слов\n",
    "        # может быть, избыточно\n",
    "        if word in tokens:\n",
    "            tokens[word] += [i]\n",
    "        else:\n",
    "            tokens.update({word: [i]})\n",
    "\n",
    "        if lemma in lemmas:\n",
    "            lemmas[lemma] += [i]\n",
    "        else:\n",
    "            lemmas.update({lemma: [i]})\n",
    "\n",
    "        df2 = pd.concat([df2, pd.DataFrame({\"token\": word,\n",
    "                                            \"lemma\": lemma,\n",
    "                                            \"pos\": form.pos,\n",
    "                                            \"tag\": form.tag\n",
    "                                           },\n",
    "                                            index=[i])])\n",
    "        i += 1\n",
    "\n",
    "    # возвращаю словарь, чтобы удобно побить на датафрейм\n",
    "    return {\"tokens\": tokens, \"lemmas\": lemmas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "152ac829-f999-4477-bda3-58d54c307942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-kutuzovskii-p...</td>\n",
       "      <td>Кутузовский план Кремля (27. 12. 2011). Запись...</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>Начну, простите, с конца.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-kutuzovskii-p...</td>\n",
       "      <td>Кутузовский план Кремля (27. 12. 2011). Запись...</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>Да, митинги 10-го и 24-го декабря – это замеча...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-kutuzovskii-p...</td>\n",
       "      <td>Кутузовский план Кремля (27. 12. 2011). Запись...</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>У России был один приближенный к серьезному ша...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-kutuzovskii-p...</td>\n",
       "      <td>Кутузовский план Кремля (27. 12. 2011). Запись...</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>Немного снижая пафос, можно было бы вспомнить ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://vk.com/@evgenyponasenkov-kutuzovskii-p...</td>\n",
       "      <td>Кутузовский план Кремля (27. 12. 2011). Запись...</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>Собственно на этом я бы и завершил статью, одн...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://vk.com/@evgenyponasenkov-kutuzovskii-p...   \n",
       "1  https://vk.com/@evgenyponasenkov-kutuzovskii-p...   \n",
       "2  https://vk.com/@evgenyponasenkov-kutuzovskii-p...   \n",
       "3  https://vk.com/@evgenyponasenkov-kutuzovskii-p...   \n",
       "4  https://vk.com/@evgenyponasenkov-kutuzovskii-p...   \n",
       "\n",
       "                                               title        date  \\\n",
       "0  Кутузовский план Кремля (27. 12. 2011). Запись...  2021-02-24   \n",
       "1  Кутузовский план Кремля (27. 12. 2011). Запись...  2021-02-24   \n",
       "2  Кутузовский план Кремля (27. 12. 2011). Запись...  2021-02-24   \n",
       "3  Кутузовский план Кремля (27. 12. 2011). Запись...  2021-02-24   \n",
       "4  Кутузовский план Кремля (27. 12. 2011). Запись...  2021-02-24   \n",
       "\n",
       "                                            sentence  \n",
       "0                          Начну, простите, с конца.  \n",
       "1  Да, митинги 10-го и 24-го декабря – это замеча...  \n",
       "2  У России был один приближенный к серьезному ша...  \n",
       "3  Немного снижая пафос, можно было бы вспомнить ...  \n",
       "4  Собственно на этом я бы и завершил статью, одн...  "
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"sent_combined.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "68658c19-c422-4c7f-9572-372352c729df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pymorphy2.opencorpora_dict.wrapper:Loading dictionaries from C:\\Users\\Maloy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymorphy2_dicts_ru\\data\n",
      "INFO:pymorphy2.opencorpora_dict.wrapper:format: 2.4, revision: 417127, updated: 2020-10-11T15:05:51.070345\n",
      "INFO:pymorphy2.opencorpora_dict.wrapper:Loading dictionaries from C:\\Users\\Maloy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pymorphy2_dicts_ru\\data\n",
      "INFO:pymorphy2.opencorpora_dict.wrapper:format: 2.4, revision: 417127, updated: 2020-10-11T15:05:51.070345\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'[^\\d\\W]+')\n",
    "from rnnmorph.predictor import RNNMorphPredictor\n",
    "\n",
    "predictor = RNNMorphPredictor(language=\"ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "33da2f49-709e-4eb6-a62e-f3b02c420fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████▌                                                           | 5473/26343 [25:18<1:36:31,  3.60it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.29 MiB for an array with shape (4, 107659) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [604]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m:[], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlemma\u001b[39m\u001b[38;5;124m\"\u001b[39m:[] , \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m\"\u001b[39m:[], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtag\u001b[39m\u001b[38;5;124m\"\u001b[39m:[]})\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#t = pd.DataFrame(df.sentence.iloc[:10].progress_apply(preprocess).values)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m t \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m      6\u001b[0m t[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlemmas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m t[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlemmas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      7\u001b[0m t[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m t[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\std.py:814\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[1;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(df, df_function)(wrapper, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    816\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\std.py:809\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    804\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[0;32m    808\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Input \u001b[1;32mIn [593]\u001b[0m, in \u001b[0;36mpreprocess\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m         lemmas\u001b[38;5;241m.\u001b[39mupdate({lemma: [i]})\n\u001b[1;32m---> 24\u001b[0m     df2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtoken\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlemma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlemma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtag\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlemmas\u001b[39m\u001b[38;5;124m\"\u001b[39m: lemmas}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:359\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03mConcatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03malong the other axes.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03mValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    346\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    347\u001b[0m     objs,\n\u001b[0;32m    348\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    356\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    357\u001b[0m )\n\u001b[1;32m--> 359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:592\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    588\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    590\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 592\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy:\n\u001b[0;32m    596\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\concat.py:231\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    225\u001b[0m vals \u001b[38;5;241m=\u001b[39m [ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units]\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_extension:\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# _is_uniform_join_units ensures a single dtype, so\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#  we can use np.concatenate, which is more performant\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#  than concat_compat\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[39;00m\n\u001b[0;32m    234\u001b[0m     values \u001b[38;5;241m=\u001b[39m concat_compat(vals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.29 MiB for an array with shape (4, 107659) and data type object"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "df2 = pd.DataFrame({\"token\":[], \"lemma\":[] , \"pos\":[], \"tag\":[]})\n",
    "\n",
    "#t = pd.DataFrame(df.sentence.iloc[:10].progress_apply(preprocess).values)\n",
    "t = pd.DataFrame(df.sentence.progress_apply(preprocess).values)\n",
    "# обрабатываю датафрейм, запихиваю результат отдельно, чтобы отладить\n",
    "t[\"lemmas\"] = t[0].apply(lambda x: x[\"lemmas\"])\n",
    "t[\"tokens\"] = t[0].apply(lambda x: x[\"tokens\"])\n",
    "t = t.drop(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "bf0bff63-7df4-4cfc-9f57-6996bff87e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>начну</td>\n",
       "      <td>начать</td>\n",
       "      <td>VERB</td>\n",
       "      <td>Mood=Ind|Number=Sing|Person=1|Tense=Notpast|Ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>простите</td>\n",
       "      <td>простить</td>\n",
       "      <td>VERB</td>\n",
       "      <td>Mood=Imp|Number=Plur|Person=2|VerbForm=Fin|Voi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>с</td>\n",
       "      <td>с</td>\n",
       "      <td>ADP</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>конца</td>\n",
       "      <td>конец</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Case=Gen|Gender=Masc|Number=Sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>да</td>\n",
       "      <td>да</td>\n",
       "      <td>CONJ</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10441</th>\n",
       "      <td>во</td>\n",
       "      <td>в</td>\n",
       "      <td>ADP</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10442</th>\n",
       "      <td>всех</td>\n",
       "      <td>весь</td>\n",
       "      <td>DET</td>\n",
       "      <td>Case=Loc|Number=Plur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10443</th>\n",
       "      <td>сословиях</td>\n",
       "      <td>сословие</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Case=Loc|Gender=Neut|Number=Plur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10444</th>\n",
       "      <td>и</td>\n",
       "      <td>и</td>\n",
       "      <td>CONJ</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10445</th>\n",
       "      <td>профессиях</td>\n",
       "      <td>профессия</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Case=Loc|Gender=Fem|Number=Plur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10446 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            token      lemma   pos  \\\n",
       "0           начну     начать  VERB   \n",
       "1        простите   простить  VERB   \n",
       "2               с          с   ADP   \n",
       "3           конца      конец  NOUN   \n",
       "4              да         да  CONJ   \n",
       "...           ...        ...   ...   \n",
       "10441          во          в   ADP   \n",
       "10442        всех       весь   DET   \n",
       "10443   сословиях   сословие  NOUN   \n",
       "10444           и          и  CONJ   \n",
       "10445  профессиях  профессия  NOUN   \n",
       "\n",
       "                                                     tag  \n",
       "0      Mood=Ind|Number=Sing|Person=1|Tense=Notpast|Ve...  \n",
       "1      Mood=Imp|Number=Plur|Person=2|VerbForm=Fin|Voi...  \n",
       "2                                                      _  \n",
       "3                       Case=Gen|Gender=Masc|Number=Sing  \n",
       "4                                                      _  \n",
       "...                                                  ...  \n",
       "10441                                                  _  \n",
       "10442                               Case=Loc|Number=Plur  \n",
       "10443                   Case=Loc|Gender=Neut|Number=Plur  \n",
       "10444                                                  _  \n",
       "10445                    Case=Loc|Gender=Fem|Number=Plur  \n",
       "\n",
       "[10446 rows x 4 columns]"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b99382-b79c-477e-8e19-0ab3e90d3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_search(word, df=df, df2=df2):\n",
    "    v = np.vectorize(lambda x: word in x)\n",
    "    indices = np.where(v(df[\"tokens\"]) == True)[0]\n",
    "    \n",
    "    for i in indices:\n",
    "        print(i)\n",
    "        print(df.iloc[i][\"sentence\"])\n",
    "        morph = df2.iloc[i]\n",
    "        print(f\"\"\"\\tnormal form - {morph.lemma}\n",
    "        pos - {morph.pos}\n",
    "        tag - {morph.tag}\"\"\")\n",
    "        print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
