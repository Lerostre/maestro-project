{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22002cd8-8f3e-4369-8346-3c96392a9685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from functools import reduce\n",
    "from tabulate import tabulate\n",
    "\n",
    "custom_diff = lambda z: reduce(lambda x, y: abs(x - y), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4874e83-f207-479f-bb0b-d8ba98bccb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consecutive(x):\n",
    "    if len(x) == 2:\n",
    "        # если два, то вырождается\n",
    "        return 1 if x[-1] - x[0] == 1 else 0\n",
    "    if len(x) > 2:\n",
    "        return 1 if (x[0] < x[-1]) and (len(x)*(x[0]+x[-1])/2 == sum(x)) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b08f1a22-13f7-413a-9322-66c2b3871f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consecutive([2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "39bc1fdd-67b9-4e15-b9dc-9e8e38adbfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(request, df=sents):\n",
    "    sub_req = request.split()\n",
    "\n",
    "    el_chars = {}\n",
    "    for element in sub_req:\n",
    "        with_pos = False\n",
    "        if element[0] == '\"':\n",
    "            mode = \"lemmas\"\n",
    "        elif element[0].isascii():\n",
    "            mode = \"poss\"\n",
    "        else:\n",
    "            mode = \"tokens\"\n",
    "        if \"+\" in element:\n",
    "            with_pos = True\n",
    "        print(element, mode)\n",
    "        el_chars.update({element: word_search(element=element,\n",
    "                                              sent_df=df, mode=mode,\n",
    "                                              with_pos=with_pos)})\n",
    "        \n",
    "    if len(el_chars) == 1:\n",
    "        sent, word_indices = list(el_chars[request].keys()), list(el_chars[request].values())\n",
    "        print_out(sent, word_indices)\n",
    "\n",
    "    else:\n",
    "        common_sents = list(reduce(lambda x, y: x & y.keys(), el_chars.values()))\n",
    "\n",
    "        for sent in common_sents:\n",
    "            # беру разницу элементов массива, она должна быть равна длине массива -1\n",
    "            listik = []\n",
    "            for key in el_chars:\n",
    "                listik.append(el_chars[key][sent])\n",
    "            grid = np.array(np.meshgrid(*listik)).T.reshape(-1, len(el_chars))\n",
    "            print(grid)\n",
    "            diffs = np.apply_along_axis(consecutive, arr=grid, axis=1)\n",
    "            print(diffs)\n",
    "            word_indices = diffs[np.where(diffs == 1)]\n",
    "            if word_indices.size > 0:\n",
    "                print_out(sent, word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "7f539c88-449e-47d1-9a17-1585756a771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(sent_indice, word_indice, df=meta):\n",
    "    if sent_indice:\n",
    "        row = df.iloc[sent_indice].reset_index()\n",
    "        np.apply_along_axis(lambda a: print(a), arr=row, axis=1)\n",
    "    #print(row.sentence)\n",
    "    #print(row.title)\n",
    "    #print(row.date)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "6b13f1f3-934d-4eb8-8ec7-9672d68ec19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_search(element, sent_df=sents, word_df=words, mode=\"tokens\", with_pos=False):\n",
    "    \n",
    "    if mode == \"lemmas\":\n",
    "        element = element[1:-1]\n",
    "\n",
    "    if with_pos:\n",
    "        word, pos = element.split(\"+\")\n",
    "        word_indices = word_search(word, sent_df, word_df, mode)\n",
    "        pos_indices = word_search(pos, sent_df, word_df, mode=\"poss\")\n",
    "        indices = word_indices.keys() & pos_indices.keys()\n",
    "        morph_indices = []\n",
    "        for sent in indices:\n",
    "            morph_indices.append(list(set(word_indices[sent]) & set(pos_indices[sent])))\n",
    "\n",
    "    else:\n",
    "        v = np.vectorize(lambda x: element in x)\n",
    "        indices = np.where(v(sent_df[mode]) == True)[0]\n",
    "        row = sent_df.iloc[indices]\n",
    "        morph_indices = row[mode].apply(lambda x: x[element])\n",
    "        if with_pos:\n",
    "        #print(row[mode].apply(lambda x: x[word]))  # индексы находятся списками\n",
    "            morph = word_df.iloc[morph_indices.sum()]\n",
    "            u = np.vectorize(lambda x: x == pos)\n",
    "\n",
    "    if not any(morph_indices):\n",
    "        indices = []\n",
    "\n",
    "    return dict(zip(indices, morph_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c42c331-cda2-4d95-8692-1848051fc818",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"sents_meta.csv\")\n",
    "sents = pd.read_csv(\"parsed_sents.csv\")\n",
    "sents = sents.applymap(lambda x: ast.literal_eval(x))\n",
    "words = pd.read_csv(\"morph_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f4726ae-4d5e-4c73-93dc-36477ca30d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'прививать': [105356],\n",
       " 'апельсин': [105357],\n",
       " 'к': [105358],\n",
       " 'ель': [105359],\n",
       " 'и': [105360],\n",
       " 'надеяться': [105361],\n",
       " 'на': [105362],\n",
       " 'добрый': [105363],\n",
       " 'плод': [105364]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents.iloc[5346].lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2cd8c129-e208-49c2-a15d-84aa455a6dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.to_csv(\"sents_meta.csv\", index=0)\n",
    "sents.to_csv(\"whyyyyyyy.csv\", index=0)\n",
    "words.to_csv(\"morph_info.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a7af98-c6e5-437d-9670-eb2f858cb1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_search('знать+NOUN', sent_df=sents, word_df=words, mode=\"tokens\", with_pos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dedf2e-0c67-46e2-9093-3ca5ea3bcba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://stackoverflow.com/questions/24893977/whats-the-best-way-to-regex-replace-a-string-in-python-but-keep-its-case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46b4455a-c350-4272-98ed-018a7307e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def replace_keep_case(word, replacement, text):\n",
    "    def func(match):\n",
    "        g = match.group()\n",
    "        if g.islower(): return replacement.lower()\n",
    "        if g.istitle(): return replacement.title()\n",
    "        if g.isupper(): return replacement.upper()\n",
    "        return replacement      \n",
    "    return re.sub(word, func, text, flags=re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d161e02-2b89-4df4-9ace-522c3a8ad045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spam with spam, bacon and spam are good for breakfast... SPAM!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Eggs with eggs, bacon and spam are good for breakfast... EGGS!\"\n",
    "replace_keep_case(\"eggs\", \"spam\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84ec62b6-28f0-4d94-88df-20bd146c8673",
   "metadata": {},
   "outputs": [],
   "source": [
    "element = \"да\"\n",
    "\n",
    "v = np.vectorize(lambda x: element in x)\n",
    "indices = np.where(v(sents[\"tokens\"]) == True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6c2b156d-e59d-48ac-bb2f-cce20b550af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'богачи': [44028],\n",
       " 'и': [44029, 44038, 44043],\n",
       " 'знать': [44030],\n",
       " 'вообще': [44031],\n",
       " 'сваливали': [44032],\n",
       " 'бремя': [44033],\n",
       " 'войны': [44034],\n",
       " 'на': [44035],\n",
       " 'пролетария': [44036],\n",
       " 'как': [44037],\n",
       " 'везде': [44039],\n",
       " 'причем': [44040],\n",
       " 'обогащались': [44041],\n",
       " 'поставщики': [44042],\n",
       " 'банкиры': [44044]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents.iloc[2131].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3df0a123-cc93-49bc-95fd-531e31d757d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents.iloc[2131].poss[\"NOUN\"] = [44028, 44030, 44033, 44034, 44036, 44042, 44044]\n",
    "sents.iloc[2131].poss[\"VERB\"] = [44032, 44041]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d647f206-27bd-4400-a365-2e7bc943302c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Case=Nom|Gender=Masc|Number=Plur'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.iloc[44028].tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7f56f757-3144-4429-bdc5-2ec787d8eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "words.iloc[44030].pos = \"NOUN\"\n",
    "words.iloc[44030].tag = \"Case=Nom|Gender=Fem|Number=Sing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bf3b95-adf1-48ff-90e6-531ab3aa682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents.ro_csv(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "631be997-eb2d-40cf-aad0-5e8788baf220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consecutive([441796, 441799])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4c2fe26-d0df-4b31-8071-e14636aa2ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "883595"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(441796+441799)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef6371f5-3864-4e83-99c1-74e476edf202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ты tokens\n",
      "был tokens\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 18 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "query = \"ты был\"\n",
    "\n",
    "results = search(query, sents, words, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39a769ca-f103-480a-bc51-954d049233a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "вот tokens\n",
      "как tokens\n"
     ]
    }
   ],
   "source": [
    "query = \"вот как\"\n",
    "\n",
    "results = search(query, sents, words, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efc13945-e601-4078-8d17-879598a1ff6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token                                             простите\n",
       "lemma                                             простить\n",
       "pos                                                   VERB\n",
       "tag      Mood=Imp|Number=Plur|Person=2|VerbForm=Fin|Voi...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40069234-5393-4cdb-9d5d-6476ae11eaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['начну',\n",
       "        'Mood=Ind|Number=Sing|Person=1|Tense=Notpast|VerbForm=Fin|Voice=Act'],\n",
       "       ['простите',\n",
       "        'Mood=Imp|Number=Plur|Person=2|VerbForm=Fin|Voice=Act'],\n",
       "       ['с', '_'],\n",
       "       ...,\n",
       "       ['эпиграфа', 'Case=Gen|Gender=Masc|Number=Sing'],\n",
       "       ['их', '_'],\n",
       "       ['смысле', 'Case=Loc|Gender=Masc|Number=Sing']], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[[\"token\", \"tag\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8bdc4e5d-561c-41d7-a6a8-9814361170cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "def get_range(obj):\n",
    "    if obj:\n",
    "        return range(min(obj)[0], max(obj)[0]+1)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "707482b4-5ed3-49ab-8c29-73276ed71e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "def get_capitals(obj):\n",
    "    if obj:\n",
    "        return int(min(obj)[0])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "31c1add2-2f66-4e7c-8edc-24d304bae3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(sents.tokens[0].values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d62c5ebc-39eb-4e01-8847-e9fd3e05f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals = sents[\"tokens\"].apply(lambda x: get_capitals(x.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "dcd30ec0-5505-48a9-961d-d3ad951be127",
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals = capitals.dropna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "80a5a06b-9a22-47c4-9a9c-d05db1a4680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "capitalized = words.iloc[capitals]\n",
    "capitalized = capitalized.token.apply(lambda x: x.capitalize()).rename(\"caps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "84455507-e644-4727-a8f3-48b2f5eaba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "words[\"caps\"] = pd.concat([words.drop(capitals).token, capitalized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e05d381b-59e1-4e40-909f-1b69bc0958f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "capitalized = capitalized.token.apply(lambda x: x.capitalize()).rename(\"caps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b431837-6b99-467e-8b8d-ff64218b028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "capitalized = capitalized.token.apply(lambda x: x.capitalize()).remame(\"caps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "deb4ba69-db8f-4042-aec4-a4f0925917f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sents[\"tokens\"].apply(lambda x: get_range(x.values())).rename(\"ranges\")\n",
    "sents_ranged = pd.concat([sents, a], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "f16818b0-7e07-41e8-9569-a2b2e0d3fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = lambda x: f'<div class=\"tooltip2\">{x[0]}<span class=\"tooltiptext2\">{x[1]}</span></div>'\n",
    "\n",
    "tooltips = np.apply_along_axis(da, arr=words[[\"caps\", \"tag\"]].values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "3c633605-5de7-4d06-9aa9-477ae3fc2b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tooltipped_words = pd.concat([words, pd.DataFrame({\"tooltips\": tooltips})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "557400a2-5cde-4680-866f-ae309cd33b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ramble_tips(tokens_range, meta_tooltips=tooltipped_words.tooltips):\n",
    "    if tokens_range:\n",
    "        return \" \".join(meta_tooltips[token_idx] for token_idx in tokens_range)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "ce94511f-d701-49c9-ba29-44358ced53bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[\"tooltipped\"] = sents_ranged.ranges.apply(ramble_tips).rename(\"tooltipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daedf28-bf28-4825-acfb-3c1f779e9a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.tooltipped[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "b2b0490a-91eb-446b-a11e-631965938130",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_tooltipped = pd.concat([meta, sents_ranged.ranges.apply(ramble_tips).rename(\"tooltipped\")], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "3f32fe75-d767-474a-9e9a-fc7894422527",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.to_csv(\"meta_tooltipped.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "3d161ef5-efdc-4f78-b06b-dffa0190aa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tooltipped_words.iloc[:, [0, -1]].to_csv(\"tooltips.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "36aa43e7-ff35-4e01-a734-3379b6a252f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from markupsafe import Markup\n",
    "value = Markup('<strong>The HTML String</strong>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "7f7fdce9-4a63-4f4a-a906-f810606f70a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tooltipped_words.to_csv(\"tooltipped_words.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4b093e0f-8741-4561-8b85-258236de9fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div class=\"tooltip\">простите<span class=\"tooltiptext\">Mood=Imp|Number=Plur|Person=2|VerbForm=Fin|Voice=Act</span></div>\"'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tooltip_wrap(1, word_df=words, meta_df=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8155b848-b142-4f57-b79e-80632b3ed434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(zip(results[0::2], results[1::2]))[::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "044273be-f601-4725-b4dd-c8dad03e8b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[0], [1], [2], [3]]\n",
    "flat_list = [item for sublist in a for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f40db793-0e1c-4bad-90fc-4eee295053e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    l = list(x.values())\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "11729555-cacf-4155-bae4-b96d7d91ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dict = sents.lemmas.apply(flatten).explode().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aad82946-c68f-41d7-9110-e92499ff54c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = pd.concat([words, pd.Series(list(sent_dict.index))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f80f078-8059-4a97-af3b-c6c9a4979310",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_search(\"NOUN\", mode=\"poss\", sent_df=sents, word_df=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6718b112-35b5-4805-abcc-da2dac0f1736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.48 ms ± 112 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "element = \"я\"\n",
    "\n",
    "v = np.vectorize(lambda x: element in x)\n",
    "indices = np.where(v(sents[\"tokens\"]) == True)[0]\n",
    "row = sents.iloc[indices]\n",
    "morph_indices = row[\"tokens\"].apply(lambda x: x[element])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c8a81215-1279-4daa-a5b2-32d7a125daa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.2 ms ± 196 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "temp = new_words[new_words[\"token\"] == element]\n",
    "morph_indices1 = list(temp.index)\n",
    "indices1 = temp[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "206750cc-ae27-44dc-8f1e-4b25d4766d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(indices == indices1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b2da52e5-c7b8-421d-862c-59134e5d60df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from functools import reduce\n",
    "import pymorphy2\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "\n",
    "def consecutive(x):\n",
    "    if len(x) == 2:\n",
    "        # если два, то вырождается\n",
    "        return 1 if x[-1] - x[0] == 1 else 0\n",
    "    if len(x) > 2:\n",
    "        return 1 if (x[0] < x[-1]) and (len(x)*(x[0]+x[-1])/2 == sum(x)) else 0\n",
    "\n",
    "    \n",
    "def search(request, sent_df, word_df, meta_df):\n",
    "    sub_req = request.split()\n",
    "    info = []\n",
    "\n",
    "    el_chars = {}\n",
    "    for element in sub_req:\n",
    "        with_pos = False\n",
    "        if element[0] == '\"':\n",
    "            mode = \"tokens\"\n",
    "        elif element[0].isascii():\n",
    "            mode = \"poss\"\n",
    "        else:\n",
    "            mode = \"lemmas\"\n",
    "        if \"+\" in element:\n",
    "            with_pos = True\n",
    "        print(element, mode)\n",
    "        el_chars.update({element: word_search(element=element,\n",
    "                                              sent_df=sent_df,\n",
    "                                              word_df=word_df,\n",
    "                                              mode=mode,\n",
    "                                              with_pos=with_pos)})\n",
    "        \n",
    "    if len(el_chars) == 1:\n",
    "        sents, word_indices = list(el_chars[request].keys()), list(el_chars[request].values())\n",
    "        for sent in sents:\n",
    "            new_info = extract_info(sent, word_indices, meta_df, word_df, 1)\n",
    "            if new_info:\n",
    "                info.append(new_info)\n",
    "\n",
    "    else:\n",
    "        common_sents = list(reduce(lambda x, y: x & y.keys(), el_chars.values()))\n",
    "\n",
    "        for sent in common_sents:\n",
    "            listik = []\n",
    "            for key in el_chars:\n",
    "                listik.append(el_chars[key][sent])\n",
    "            grid = np.array(np.meshgrid(*listik)).T.reshape(-1, len(el_chars))\n",
    "            diffs = np.apply_along_axis(consecutive, arr=grid, axis=1)\n",
    "            word_indices = diffs[np.where(diffs == 1)]\n",
    "            if word_indices.size > 0:\n",
    "                info.append(extract_info(sent, word_indices, meta_df, word_df))\n",
    "\n",
    "    return info\n",
    "\n",
    "\n",
    "def replace_keep_case(word, replacement, text):\n",
    "    def func(match):\n",
    "        g = match.group()\n",
    "        if g.islower(): return replacement.lower()\n",
    "        if g.istitle(): return replacement.title()\n",
    "        if g.isupper(): return replacement.upper()\n",
    "        return replacement      \n",
    "    return re.sub(rf\"\\b{word}\\b\", func, text, flags=re.I)\n",
    "\n",
    "\n",
    "def highlight(sentence, string):\n",
    "    sent_check = sentence.lower()\n",
    "    \n",
    "    if not string[0].isascii() and f\"<mark>{string}</mark>\".lower() not in sent_check:\n",
    "        return replace_keep_case(string, f'<mark>{string}</mark>', sentence)\n",
    "    else:\n",
    "        return sentence\n",
    "\n",
    "\n",
    "def highlight2(sentence, string):\n",
    "    red = \"\\033[31m\"\n",
    "    nul = \"\\033[0m\"\n",
    "    sentence = re.sub(\n",
    "        r\"\\b({})\\b\".format(re.escape(string)),\n",
    "        r\"{}\\1{}\".format(red, nul),\n",
    "        sentence,\n",
    "        flags=re.I,\n",
    "    )\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def extract_info(sent_indice, word_indice, meta_df, word_df, num=2):\n",
    "    if sent_indice:\n",
    "        row = meta_df.iloc[sent_indice]\n",
    "        sent = row.sentence\n",
    "        if num == 1:\n",
    "            words = [word_df.iloc[item].token for sublist in word_indice for item in sublist]\n",
    "            for word in words:\n",
    "                sent = highlight(sent, word)\n",
    "        #print(word_df.iloc[word_indice].pos)\n",
    "        return {\"index\": str(sent_indice), \"sents\": sent,\n",
    "               \"titles\": row.title, \"dates\": row.date}\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def word_search(element, sent_df, word_df, mode=\"tokens\", with_pos=False, is_normal=False):\n",
    "    \n",
    "    res = {}\n",
    "    \n",
    "    print(element, mode, with_pos)\n",
    "\n",
    "    if mode == \"lemmas\" and not is_normal:\n",
    "        elements = query_parse(element)\n",
    "        for el in elements:\n",
    "            res.update(word_search(el, sent_df, word_df, mode, with_pos, is_normal=True))\n",
    "        return res\n",
    "\n",
    "    elif mode == \"tokens\":\n",
    "        element = element[1:-1]\n",
    "\n",
    "    if with_pos:\n",
    "        indices = []\n",
    "        word, pos = element.split(\"+\")\n",
    "        word_indices = word_search(word, sent_df, word_df, mode)\n",
    "        pos_indices = word_search(pos.upper(), sent_df, word_df, mode=\"poss\")\n",
    "        indices_candidates = word_indices.keys() & pos_indices.keys()\n",
    "        morph_indices = []\n",
    "        for sent in indices_candidates:\n",
    "            candidate = list(set(word_indices[sent]) & set(pos_indices[sent]))\n",
    "            if candidate:\n",
    "                indices.append(sent)\n",
    "                morph_indices.append(candidate)\n",
    "\n",
    "    else:\n",
    "        v = np.vectorize(lambda x: element in x)\n",
    "        indices = np.where(v(sent_df[mode]) == True)[0]\n",
    "        row = sent_df.iloc[indices]\n",
    "        morph_indices = row[mode].apply(lambda x: x[element])\n",
    "\n",
    "    if not any(morph_indices):\n",
    "        indices = []\n",
    "\n",
    "    return dict(zip(indices, morph_indices))\n",
    "\n",
    "\n",
    "def query_parse(word):\n",
    "    variants = []\n",
    "\n",
    "    for i in morph.parse(word):\n",
    "        form = i.normal_form\n",
    "        if form not in variants:\n",
    "            variants.append(form)\n",
    "\n",
    "    return variants\n",
    "\n",
    "\n",
    "def morphy_converter(x):\n",
    "    converter = {\"ADJF\": \"ADJ\", \"ADJS\": \"ADJ\", \"COMP\": \"ADJ\",\n",
    "                \"INFN\": \"VERB\", \"PRTF\": \"VERB\", \"PRTS\": \"VERB\", \"GRND\": \"VERB\",\n",
    "                \"NUMR\": \"NUM\", \"ADVB\": \"ADV\", \"PREP\": \"ADP\", \"PTCL\": \"PART\"}\n",
    "    return converter[x] if x in converter else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "807ced9d-add4-4aa3-bbe0-8d6429775911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight(sentence, string):\n",
    "    # не работает, если слово есть в предложении, но без чего-то\n",
    "    words = \" \".join(x for x in string.split(\"+\")).split()\n",
    "    string_length = len(words)\n",
    "    \n",
    "    sent_words = sentence.split()\n",
    "    sent_idx = sent_words.index(words[0])\n",
    "    words_to_change = \" \".join(sent_words[sent_idx+x] for x in range(string_length))\n",
    "    \n",
    "    print(words_to_change)\n",
    "    \n",
    "    return replace_keep_case(words_to_change, f'<mark>{words_to_change}</mark>', sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d880f11-fed3-428d-bf22-a13a8bffcbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ели lemmas False\n",
      "есть lemmas False\n",
      "ель lemmas False\n"
     ]
    }
   ],
   "source": [
    "res = word_search(\"ели\", sents, words, mode=\"lemmas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6447805-70e5-4afd-97a9-1aedba8cc7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5346: [105359], 26041: [476152]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_search(\"ель\", sents, words, mode=\"lemmas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c17e5e-c781-4123-8aa7-5b43d84bf115",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_search(\"есть\", sents, words, mode=\"lemmas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "833bcdfa-52c6-49e9-863c-32a6ac565f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = {\"да\" : 1}\n",
    "x = {\"нет\": 2}\n",
    "z = {\"ах\": 2}\n",
    "a = {\"sх\": 3}\n",
    "\n",
    "x.update(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7194ba60-b1ab-481b-acab-e1fb0e39aa9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'replace_with_case' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mreplace_with_case\u001b[49m(sent, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mда\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'replace_with_case' is not defined"
     ]
    }
   ],
   "source": [
    "replace_with_case(sent, \"да\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3154f9d7-c298-4b48-979a-c9c61d45b258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ели+NOUN lemmas\n",
      "ели+NOUN lemmas True\n",
      "ели+noun lemmas True\n",
      "ели lemmas False\n",
      "есть lemmas False\n",
      "ель lemmas False\n",
      "NOUN poss False\n"
     ]
    }
   ],
   "source": [
    "query = 'ели+NOUN'\n",
    "\n",
    "results = search(query, sents, words, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a966663-05fb-45d3-86c3-cc0a1164355b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': '26041',\n",
       "  'sents': 'Вечером, в полях, где приходится останавливаться для ночного отдыха, они укладываются у подножия <mark>елей</mark>, белых берез или под повозками, кавалеристы с уздой в руках, пехотинцы оставляют на спине ранец и прижимают к себе оружие; точно как в стаде они плотно прижимаются друг к другу и обнимаются, чтобы разогреться.',\n",
       "  'titles': 'Правда о войне 1812 года',\n",
       "  'dates': '2004'},\n",
       " {'index': '8278',\n",
       "  'sents': 'Наконец выходит (из чего, по каким фактам? — прим, мое, Е.П.), что господин сей Лезер более нам вреден, нежели полезен, почему я счел за нужное немедленно отправить к в. с., прося вас всепокорнейшее приказать за ним присматривать и не давать никакого способа иметь переписку с родственниками своими или с кем ни на <mark>есть</mark>».',\n",
       "  'titles': 'Первая научная история войны 1812 года',\n",
       "  'dates': '2018'},\n",
       " {'index': '5346',\n",
       "  'sents': 'Прививают апельсины к <mark>елям</mark> и надеются на добрые плоды.',\n",
       "  'titles': 'Первая научная история войны 1812 года',\n",
       "  'dates': '2018'}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a79167f3-7102-4ff9-b51f-9e698d167c72",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sent_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m word_search(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mель\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43msent_df\u001b[49m, word_df, mode)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sent_df' is not defined"
     ]
    }
   ],
   "source": [
    "word_search(\"ель\", sent_df, word_df, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "affc6be7-3443-46ef-bc1e-cefb22d9f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight(sentence, string):\n",
    "    print(string[0])\n",
    "    if string[0].isascii():\n",
    "        \n",
    "    else:\n",
    "        return replace_keep_case(string, f'<mark>{string}</mark>', sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "edd271e1-4497-4620-9b80-4d5047828ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01e9c474-971c-4266-8dcb-6940d352352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4e177f6-85b8-4b8d-90a2-c5f71ede54f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_parse(word):\n",
    "    variants = []\n",
    "\n",
    "    for i in morph.parse(word):\n",
    "        form = i.normal_form\n",
    "        if form not in variants:\n",
    "            variants.append(form)\n",
    "\n",
    "    return variants\n",
    "\n",
    "\n",
    "def morphy_converter(x):\n",
    "    converter = {\"ADJF\": \"ADJ\", \"ADJS\": \"ADJ\", \"COMP\": \"ADJ\",\n",
    "                \"INFN\": \"VERB\", \"PRTF\": \"VERB\", \"PRTS\": \"VERB\", \"GRND\": \"VERB\",\n",
    "                \"NUMR\": \"NUM\", \"ADVB\": \"ADV\", \"PREP\": \"ADP\", \"PTCL\": \"PART\"}\n",
    "    return converter[x] if x in converter else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edc6d636-51d9-450b-b3b5-cc643fe2c0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['есть', 'ель']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_parse(\"ели\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b576bb6-9d41-4c41-ac82-3dd52791b444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphy_converter(x):\n",
    "    converter = {\"ADJF\": \"ADJ\", \"ADJS\": \"ADJ\", \"COMP\": \"ADJ\",\n",
    "                \"INFN\": \"VERB\", \"PRTF\": \"VERB\", \"PRTS\": \"VERB\", \"GRND\": \"VERB\",\n",
    "                \"NUMR\": \"NUM\", \"ADVB\": \"ADV\", \"PREP\": \"ADP\", \"PTCL\": \"PART\"}\n",
    "    return converter[x] if x in converter else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7bb694c1-6d1c-44cb-abf6-b97451a5e756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<normal_form=есть; word=ели; pos=VERB; tag=Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act; score=0.9919>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict([\"ели\"])[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1efa7285-c410-4735-a5c4-5a9b0a9b90b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnnmorph.predictor import RNNMorphPredictor\n",
    "\n",
    "predictor = RNNMorphPredictor(language=\"ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8cb8e05d-c4e3-4ef1-b248-c84d201dca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = words.drop(list(words[(words.token == \"е\") | (words.token == \"п\")].index), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a29285bd-8925-4d4f-8de3-1467444750b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOUN    472\n",
       "CONJ    200\n",
       "ADP      59\n",
       "ADJ      44\n",
       "VERB     42\n",
       "ADV      41\n",
       "PART     36\n",
       "INTJ     27\n",
       "PRON      5\n",
       "DET       2\n",
       "NUM       1\n",
       "Name: pos, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[(words.token == \"п\")].pos.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "40f7a5d7-7fbd-4403-ae47-0d3a14e59b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = words.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4d312fa5-88a4-4216-baf6-fa5f5f58df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight(sentence, string):\n",
    "    if string[0] == '\"':\n",
    "        string = string[1:-1]\n",
    "    if string[0].isascii():\n",
    "        return sentence\n",
    "    else:\n",
    "        return replace_keep_case(string, f'<mark>{string}</mark>', sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2128fa46-6d04-4473-9fe6-e4892999a8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "\"хочу\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Я <mark>хочу</mark> пиццы!'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlight(\"Я хочу пиццы!\", '\"хочу\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a6b3fccb-03d0-4f5a-9d25-2795c80ae389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'хочу'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '\"хочу\"'\n",
    "a[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d3d9ca-c936-4425-80ed-3f07a3a1a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "я был\n",
    "хайлайты"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
